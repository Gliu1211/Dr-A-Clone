{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pypdf import PdfReader\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gramformer for fixing sentences (kinda takes a long time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:796: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:471: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Gramformer] Grammar error correct/highlight model loaded..\n"
     ]
    }
   ],
   "source": [
    "from gramformer import Gramformer\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "  torch.manual_seed(seed)\n",
    "  if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "usingGramFormer = True\n",
    "gf = Gramformer(models = 1, use_gpu=False) # 1=corrector, 2=detector\n",
    "def fixed_sentence(sentence: str) -> str:\n",
    "    new_sentence:str = gf.correct(sentence, max_candidates=1).pop()\n",
    "    new_sentence = sentence\n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_text(raw_text: str) -> str:\n",
    "    def fix_letter_spacing(text):\n",
    "        letters_to_fix = [\n",
    "            char for char in string.ascii_letters if char not in ['A', 'a', 'I', 'i']]\n",
    "\n",
    "        for letter in letters_to_fix:\n",
    "            text = text.replace(f\" {letter} \", f\"{letter} \")\n",
    "            text = text.replace(f\" {letter}.\", f\"{letter}.\")\n",
    "\n",
    "        return text\n",
    "\n",
    "    trimmed_text = raw_text.strip()\n",
    "    trimmed_text = \" \".join(trimmed_text.split())\n",
    "    trimmed_text = trimmed_text.replace(\" .\", \".\")\n",
    "    trimmed_text = trimmed_text.replace(\" ,\", \",\")\n",
    "    trimmed_text = trimmed_text.replace(\" )\", \")\")\n",
    "    trimmed_text = trimmed_text.replace(\"( \", \"(\")\n",
    "    trimmed_text = trimmed_text.replace(\"-\", \"\")\n",
    "    trimmed_text = raw_text.strip()\n",
    "    trimmed_text = \" \".join(trimmed_text.split())\n",
    "    trimmed_text = fix_letter_spacing(trimmed_text)\n",
    "    return trimmed_text\n",
    "\n",
    "\n",
    "# def set_seed(seed):\n",
    "#     torch.manual_seed(seed)\n",
    "#     if torch.cuda.is_available():\n",
    "#         torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "#     set_seed(1212)\n",
    "\n",
    "\n",
    "# gf = Gramformer(models=1, use_gpu=False)  # 1=corrector, 2=detector\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document not found: apple\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all the document names\n",
    "doc_directory = \"PDFS\"\n",
    "names = os.listdir(doc_directory)\n",
    "\n",
    "# initialize dictionary\n",
    "# KEY: DOCUMENT NAME\n",
    "# VALUE (1-indexed): [START PAGE INCLUSIVE, END PAGE EXLUCISVE]\n",
    "\n",
    "\n",
    "docs: dict[str, (int, int)] = {'Bridging Cognition and Socioculturalism Within Conceptual Change Research- Unnecessary Foray or Unachievable Feat.pdf': (2, 6),\n",
    "                               'Cognitive Affective Engagement Model of Multiple Source Use.pdf': (2, 14),\n",
    "                               'Confronting the Challenges of Undergraduates’ Argumentation Writing in a “Learning How to Learn” Course.pdf': (2, 30),\n",
    "                               'Engagement and literacy- reading between the lines.pdf': (2, 7),\n",
    "                               'Evolution of a Learning Theory- In Praise of Scientific Speculation.pdf': (2, 18),\n",
    "                               'Hybridizing Psychological Theories- Weighing the Ends Against the Means.pdf': (2, 11),\n",
    "                               'Individual differences in college-age learners- The importance of relational reasoning for learning and assessment in higher education.pdf': (2, 10),\n",
    "                               'Investing a Novel Approach to Assessing Vocabulary Knowledge.pdf': (3, 33),\n",
    "                               'Leveraging What Students Know to Make Sense of Texts- What the Research Says About Prior Knowledge Activation.pdf': (2, 31),\n",
    "                               'Looking down the road- Future directions for research on depth and regulation of strategic processing.pdf': (2, 13),\n",
    "                               'Relational Reasoning in Tertiary Education- What Is Its Value and How Can It Be Assessed and Trained.pdf': (2, 12),\n",
    "                               'RR INSTRUCTION MANUAL.pdf': (2, 9),\n",
    "                               'Seeking Common Ground- Surveying the Theoretical and Empirical Landscapes for Curiosity and Interest.pdf': (2, 8),\n",
    "                               'Shared Discursive History- Rethinking Teachers as Role Models.pdf': (2, 22),\n",
    "                               'The Effects of Processing Multimodal Texts in Print and Digitally on Comprehension and Calibration.pdf': (2, 19),\n",
    "                               'The Relevance of Relevance for Learning and Performance.pdf': (2, 11),\n",
    "                               'Through Myth to Reality- Reframing Education as Academic Development.pdf': (2, 16),\n",
    "                               'What is Learning Anyway- A Topological Perspetive Considered.pdf': (2, 15),\n",
    "                               'What Research Has Revealed About Readers’ Struggles With Comprehension in the Digital Age- Moving Beyond the Phonics Versus Whole Language Debate.pdf': (2, 7),\n",
    "                               'Why This and Why Now- Introduction to the Special Issue on Metacognition, Self-Regulation, and Self-Regulated Learning.pdf': (2, 4),\n",
    "                               'Yes…But- Footnotes To Sage Advice.pdf': (2, 7),\n",
    "                               'apple': (1, 1),\n",
    "                               '“Here Be Dragons!” Mapping the Realm of Higher-Order, Critical, and Critical-Analytic Thinking.pdf': (2, 15),\n",
    "                               \"Alexander-MethodologicalGuidancePaper-2020.pdf\": (4, 18),\n",
    "                               \"The Development of Expertise- The Journey From Acclimation to Proficiency.pdf\": (2, 5),\n",
    "                               \"Analyzing and Integrating Models of Multiple Text Comprehension.pdf\": (1, 5),\n",
    "                               \"Issues of Constructs, Contexts, and Continuity- Commentary on Learning in Higher Education.pdf\": (1, 7),\n",
    "                               \"The Development of Relational Reasoning in South Korean Elementary and Middle-School Students A Cross-Sectional Investigation\": (2, 13)\n",
    "                               \n",
    "\n",
    "                               }\n",
    "\n",
    "doc_names = list(docs.keys())\n",
    "\n",
    "# double check if the keys are actually files\n",
    "exists = []\n",
    "for doc_name in doc_names:\n",
    "    path = os.path.join(doc_directory, doc_name)\n",
    "    exists.append((doc_name, os.path.exists(path)))\n",
    "\n",
    "for name, status in exists:\n",
    "    if status == False:\n",
    "        print(f'document not found: {name}')\n",
    "        docs.pop(name)\n",
    "\n",
    "doc_names = list(docs.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdfToCSV(pdfFile: str):\n",
    "\n",
    "    reader = PdfReader(f'./PDFS/{pdfFile}')\n",
    "\n",
    "    start_page: int = docs[pdfFile][0]\n",
    "    end_page: int = docs[pdfFile][1]\n",
    "    if not isinstance(start_page, int) or not isinstance(end_page, int):\n",
    "        print(\"Start page and end page must be integers.\")\n",
    "        return 0\n",
    "\n",
    "    df = pd.DataFrame(columns=[\"SENTENCE\", \"NUM_WORDS\", \"SENTENCE_TYPE\"])\n",
    "\n",
    "    pages = reader.pages[start_page-1: end_page-1]\n",
    "    sentences = []\n",
    "    for i, page in enumerate(pages):\n",
    "        raw_text = page.extract_text()\n",
    "\n",
    "        fixed_text = fix_text(raw_text)\n",
    "        # splitting sentences on both question marks and on periods\n",
    "        split_sentences = re.split(r'[.\\s?\\s]\\s+', fixed_text)\n",
    "\n",
    "        # Only add sentences that have more than 4 words\n",
    "        filtered_sentences = [\n",
    "            fixed_sentence(sentence) for sentence in split_sentences if len(sentence.split()) >= 12 and len(sentence.split()) <= 100]\n",
    "\n",
    "        # Append these filtered sentences to the existing 'sentences' list\n",
    "        sentences += filtered_sentences\n",
    "\n",
    "    df = pd.DataFrame(sentences, columns=[\"SENTENCES\"])\n",
    "    csvFile = pdfFile.replace('.pdf', '.csv')\n",
    "    # pdfFile = pdfFile[0:-4]\n",
    "\n",
    "    output_file_path = f\"CSVS/{csvFile}\"\n",
    "    csv = df.to_csv(output_file_path, index=False, encoding=\"utf8\")\n",
    "\n",
    "    # counting lines parsed\n",
    "    df = pd.read_csv(output_file_path)\n",
    "\n",
    "    # Count the number of rows\n",
    "    num_rows = len(df)\n",
    "    print(f'CSV Location:: {output_file_path}, Number of rows: {num_rows}')\n",
    "    return num_rows\n",
    "\n",
    "# test pdfToCSV\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing pdfToCSV function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# pdfToCSV('Bridging Cognition and Socioculturalism Within Conceptual Change Research- Unnecessary Foray or Unachievable Feat.pdf')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m pdfToCSV(\u001b[39m'\u001b[39;49m\u001b[39mIssues of Constructs, Contexts, and Continuity- Commentary on Learning in Higher Education.pdf\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m pdfToCSV(\u001b[39m'\u001b[39m\u001b[39mAnalyzing and Integrating Models of Multiple Text Comprehension.pdf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 24\u001b[0m, in \u001b[0;36mpdfToCSV\u001b[1;34m(pdfFile)\u001b[0m\n\u001b[0;32m     20\u001b[0m split_sentences \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msplit(\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m\u001b[39m[.\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms?\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms]\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms+\u001b[39m\u001b[39m'\u001b[39m, fixed_text)\n\u001b[0;32m     22\u001b[0m \u001b[39m# Only add sentences that have more than 4 words\u001b[39;00m\n\u001b[0;32m     23\u001b[0m filtered_sentences \u001b[39m=\u001b[39m [\n\u001b[1;32m---> 24\u001b[0m     fixed_sentence(sentence) \u001b[39mfor\u001b[39;00m sentence \u001b[39min\u001b[39;00m split_sentences \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(sentence\u001b[39m.\u001b[39msplit()) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m12\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(sentence\u001b[39m.\u001b[39msplit()) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m100\u001b[39m]\n\u001b[0;32m     26\u001b[0m \u001b[39m# Append these filtered sentences to the existing 'sentences' list\u001b[39;00m\n\u001b[0;32m     27\u001b[0m sentences \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m filtered_sentences\n",
      "Cell \u001b[1;32mIn[39], line 14\u001b[0m, in \u001b[0;36mfixed_sentence\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfixed_sentence\u001b[39m(sentence: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m---> 14\u001b[0m     new_sentence:\u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m gf\u001b[39m.\u001b[39;49mcorrect(sentence, max_candidates\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39mpop()\n\u001b[0;32m     15\u001b[0m     new_sentence \u001b[39m=\u001b[39m sentence\n\u001b[0;32m     16\u001b[0m     \u001b[39mreturn\u001b[39;00m new_sentence\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\gramformer\\gramformer.py:37\u001b[0m, in \u001b[0;36mGramformer.correct\u001b[1;34m(self, input_sentence, max_candidates)\u001b[0m\n\u001b[0;32m     34\u001b[0m         input_ids \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcorrection_tokenizer\u001b[39m.\u001b[39mencode(input_sentence, return_tensors\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m         input_ids \u001b[39m=\u001b[39m input_ids\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m---> 37\u001b[0m         preds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcorrection_model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[0;32m     38\u001b[0m             input_ids,\n\u001b[0;32m     39\u001b[0m             do_sample\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[0;32m     40\u001b[0m             max_length\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, \n\u001b[0;32m     41\u001b[0m \u001b[39m#             top_k=50, \u001b[39;49;00m\n\u001b[0;32m     42\u001b[0m \u001b[39m#             top_p=0.95, \u001b[39;49;00m\n\u001b[0;32m     43\u001b[0m             num_beams\u001b[39m=\u001b[39;49m\u001b[39m7\u001b[39;49m,\n\u001b[0;32m     44\u001b[0m             early_stopping\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     45\u001b[0m             num_return_sequences\u001b[39m=\u001b[39;49mmax_candidates)\n\u001b[0;32m     47\u001b[0m         corrected \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m     48\u001b[0m         \u001b[39mfor\u001b[39;00m pred \u001b[39min\u001b[39;00m preds:  \n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:2078\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[1;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[0;32m   2070\u001b[0m     input_ids, model_kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_expand_inputs_for_generation(\n\u001b[0;32m   2071\u001b[0m         input_ids\u001b[39m=\u001b[39minput_ids,\n\u001b[0;32m   2072\u001b[0m         expand_size\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[0;32m   2073\u001b[0m         is_encoder_decoder\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mis_encoder_decoder,\n\u001b[0;32m   2074\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m   2075\u001b[0m     )\n\u001b[0;32m   2077\u001b[0m     \u001b[39m# 13. run beam sample\u001b[39;00m\n\u001b[1;32m-> 2078\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_beam_search(\n\u001b[0;32m   2079\u001b[0m         input_ids,\n\u001b[0;32m   2080\u001b[0m         beam_scorer,\n\u001b[0;32m   2081\u001b[0m         logits_processor\u001b[39m=\u001b[39;49mprepared_logits_processor,\n\u001b[0;32m   2082\u001b[0m         stopping_criteria\u001b[39m=\u001b[39;49mprepared_stopping_criteria,\n\u001b[0;32m   2083\u001b[0m         generation_config\u001b[39m=\u001b[39;49mgeneration_config,\n\u001b[0;32m   2084\u001b[0m         synced_gpus\u001b[39m=\u001b[39;49msynced_gpus,\n\u001b[0;32m   2085\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_kwargs,\n\u001b[0;32m   2086\u001b[0m     )\n\u001b[0;32m   2088\u001b[0m \u001b[39melif\u001b[39;00m generation_mode \u001b[39m==\u001b[39m GenerationMode\u001b[39m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[0;32m   2089\u001b[0m     \u001b[39m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[0;32m   2090\u001b[0m     beam_scorer \u001b[39m=\u001b[39m BeamSearchScorer(\n\u001b[0;32m   2091\u001b[0m         batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   2092\u001b[0m         num_beams\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mnum_beams,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2098\u001b[0m         max_length\u001b[39m=\u001b[39mgeneration_config\u001b[39m.\u001b[39mmax_length,\n\u001b[0;32m   2099\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:3253\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[1;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[0;32m   3250\u001b[0m     outputs \u001b[39m=\u001b[39m stack_model_outputs(outputs_per_sub_batch, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mget_text_config())\n\u001b[0;32m   3252\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# Unchanged original behavior\u001b[39;00m\n\u001b[1;32m-> 3253\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmodel_inputs, return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m   3255\u001b[0m \u001b[39mif\u001b[39;00m synced_gpus \u001b[39mand\u001b[39;00m this_peer_finished:\n\u001b[0;32m   3256\u001b[0m     cur_len \u001b[39m=\u001b[39m cur_len \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1740\u001b[0m, in \u001b[0;36mT5ForConditionalGeneration.forward\u001b[1;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1737\u001b[0m         decoder_attention_mask \u001b[39m=\u001b[39m decoder_attention_mask\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder\u001b[39m.\u001b[39mfirst_device)\n\u001b[0;32m   1739\u001b[0m \u001b[39m# Decode\u001b[39;00m\n\u001b[1;32m-> 1740\u001b[0m decoder_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(\n\u001b[0;32m   1741\u001b[0m     input_ids\u001b[39m=\u001b[39;49mdecoder_input_ids,\n\u001b[0;32m   1742\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mdecoder_attention_mask,\n\u001b[0;32m   1743\u001b[0m     inputs_embeds\u001b[39m=\u001b[39;49mdecoder_inputs_embeds,\n\u001b[0;32m   1744\u001b[0m     past_key_values\u001b[39m=\u001b[39;49mpast_key_values,\n\u001b[0;32m   1745\u001b[0m     encoder_hidden_states\u001b[39m=\u001b[39;49mhidden_states,\n\u001b[0;32m   1746\u001b[0m     encoder_attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m   1747\u001b[0m     head_mask\u001b[39m=\u001b[39;49mdecoder_head_mask,\n\u001b[0;32m   1748\u001b[0m     cross_attn_head_mask\u001b[39m=\u001b[39;49mcross_attn_head_mask,\n\u001b[0;32m   1749\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1750\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1751\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[0;32m   1752\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[0;32m   1753\u001b[0m )\n\u001b[0;32m   1755\u001b[0m sequence_output \u001b[39m=\u001b[39m decoder_outputs[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1757\u001b[0m \u001b[39m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:1107\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[1;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1092\u001b[0m     layer_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m   1093\u001b[0m         layer_module\u001b[39m.\u001b[39mforward,\n\u001b[0;32m   1094\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1104\u001b[0m         output_attentions,\n\u001b[0;32m   1105\u001b[0m     )\n\u001b[0;32m   1106\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1107\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[0;32m   1108\u001b[0m         hidden_states,\n\u001b[0;32m   1109\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[0;32m   1110\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m   1111\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[0;32m   1112\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[0;32m   1113\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[0;32m   1114\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m   1115\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[0;32m   1116\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m   1117\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m   1118\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m   1119\u001b[0m     )\n\u001b[0;32m   1121\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:687\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    685\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 687\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[0;32m    688\u001b[0m     hidden_states,\n\u001b[0;32m    689\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    690\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    691\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    692\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[0;32m    693\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    694\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    695\u001b[0m )\n\u001b[0;32m    696\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[0;32m    697\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:594\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[0;32m    584\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    585\u001b[0m     hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    591\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    592\u001b[0m ):\n\u001b[0;32m    593\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[1;32m--> 594\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[0;32m    595\u001b[0m         normed_hidden_states,\n\u001b[0;32m    596\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[0;32m    597\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[0;32m    598\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[0;32m    599\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[0;32m    600\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[0;32m    601\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[0;32m    602\u001b[0m     )\n\u001b[0;32m    603\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[0;32m    604\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:516\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[1;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[0;32m    513\u001b[0m query_states \u001b[39m=\u001b[39m shape(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mq(hidden_states))  \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \u001b[39m# get key/value states\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m key_states \u001b[39m=\u001b[39m project(\n\u001b[0;32m    517\u001b[0m     hidden_states, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mk, key_value_states, past_key_value[\u001b[39m0\u001b[39;49m] \u001b[39mif\u001b[39;49;00m past_key_value \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    518\u001b[0m )\n\u001b[0;32m    519\u001b[0m value_states \u001b[39m=\u001b[39m project(\n\u001b[0;32m    520\u001b[0m     hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv, key_value_states, past_key_value[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    521\u001b[0m )\n\u001b[0;32m    523\u001b[0m \u001b[39m# compute scores\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\transformers\\models\\t5\\modeling_t5.py:490\u001b[0m, in \u001b[0;36mT5Attention.forward.<locals>.project\u001b[1;34m(hidden_states, proj_layer, key_value_states, past_key_value)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"projects hidden states correctly to key/query states\"\"\"\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[39mif\u001b[39;00m key_value_states \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    488\u001b[0m     \u001b[39m# self-attn\u001b[39;00m\n\u001b[0;32m    489\u001b[0m     \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(hidden_states))\n\u001b[0;32m    491\u001b[0m \u001b[39melif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    492\u001b[0m     \u001b[39m# cross-attn\u001b[39;00m\n\u001b[0;32m    493\u001b[0m     \u001b[39m# (batch_size, n_heads, seq_length, dim_per_head)\u001b[39;00m\n\u001b[0;32m    494\u001b[0m     hidden_states \u001b[39m=\u001b[39m shape(proj_layer(key_value_states))\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\akaru\\School\\Fall 2024 ML Research\\Dr. A Sentences\\Dr-A-Clone\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pdfToCSV('Bridging Cognition and Socioculturalism Within Conceptual Change Research- Unnecessary Foray or Unachievable Feat.pdf')\n",
    "pdfToCSV('Issues of Constructs, Contexts, and Continuity- Commentary on Learning in Higher Education.pdf')\n",
    "pdfToCSV('Analyzing and Integrating Models of Multiple Text Comprehension.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Location:: CSVS/Analyzing and Integrating Models of Multiple Text Comprehension.csv, Number of rows: 85\n",
      "CSV Location:: CSVS/Issues of Constructs, Contexts, and Continuity- Commentary on Learning in Higher Education.csv, Number of rows: 108\n",
      "Total rows: 193\n"
     ]
    }
   ],
   "source": [
    "# UPDATE: for pdf in docnames, where pdf isn't already in CSV's:\n",
    "\n",
    "\n",
    "def parseCSVS(avoid_reparse=True):\n",
    "    rows = 0\n",
    "    for pdf in doc_names:\n",
    "        # if the csv version of that pdf doesn't exist:\n",
    "        csv_filename = pdf.replace('.pdf', '.csv')\n",
    "        parsed_csvs = set(os.listdir('./CSVS')) if avoid_reparse else set()\n",
    "        if csv_filename not in parsed_csvs:\n",
    "            rows += pdfToCSV(pdf)\n",
    "    return rows\n",
    "\n",
    "rows = parseCSVS()\n",
    "\n",
    "print(f\"Total rows: {rows}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking The Lines Parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Alexander-MethodologicalGuidancePaper-2020.csv: 267 rows\n",
      "2. Analyzing and Integrating Models of Multiple Text Comprehension.csv: 85 rows\n",
      "3. Bridging Cognition and Socioculturalism Within Conceptual Change Research- Unnecessary Foray or Unachievable Feat.csv: 97 rows\n",
      "4. Cognitive Affective Engagement Model of Multiple Source Use.csv: 313 rows\n",
      "5. Confronting the Challenges of Undergraduates’ Argumentation Writing in a “Learning How to Learn” Course.csv: 356 rows\n",
      "6. Engagement and literacy- reading between the lines.csv: 92 rows\n",
      "7. Evolution of a Learning Theory- In Praise of Scientific Speculation.csv: 272 rows\n",
      "8. Hybridizing Psychological Theories- Weighing the Ends Against the Means.csv: 146 rows\n",
      "9. Individual differences in college-age learners- The importance of relational reasoning for learning and assessment in higher education.csv: 147 rows\n",
      "10. Investing a Novel Approach to Assessing Vocabulary Knowledge.csv: 311 rows\n",
      "11. Issues of Constructs, Contexts, and Continuity- Commentary on Learning in Higher Education.csv: 108 rows\n",
      "12. Leveraging What Students Know to Make Sense of Texts- What the Research Says About Prior Knowledge Activation.csv: 457 rows\n",
      "13. Looking down the road- Future directions for research on depth and regulation of strategic processing.csv: 202 rows\n",
      "14. Relational Reasoning in Tertiary Education- What Is Its Value and How Can It Be Assessed and Trained.csv: 311 rows\n",
      "15. RR INSTRUCTION MANUAL.csv: 60 rows\n",
      "16. Seeking Common Ground- Surveying the Theoretical and Empirical Landscapes for Curiosity and Interest.csv: 120 rows\n",
      "17. Shared Discursive History- Rethinking Teachers as Role Models.csv: 299 rows\n",
      "18. The Development of Expertise- The Journey From Acclimation to Proficiency.csv: 109 rows\n",
      "19. The Effects of Processing Multimodal Texts in Print and Digitally on Comprehension and Calibration.csv: 335 rows\n",
      "20. The Relevance of Relevance for Learning and Performance.csv: 212 rows\n",
      "21. Through Myth to Reality- Reframing Education as Academic Development.csv: 207 rows\n",
      "22. What is Learning Anyway- A Topological Perspetive Considered.csv: 368 rows\n",
      "23. What Research Has Revealed About Readers’ Struggles With Comprehension in the Digital Age- Moving Beyond the Phonics Versus Whole Language Debate.csv: 147 rows\n",
      "24. Why This and Why Now- Introduction to the Special Issue on Metacognition, Self-Regulation, and Self-Regulated Learning.csv: 44 rows\n",
      "25. Yes…But- Footnotes To Sage Advice.csv: 100 rows\n",
      "26. “Here Be Dragons!” Mapping the Realm of Higher-Order, Critical, and Critical-Analytic Thinking.csv: 205 rows\n",
      "TOTAL ROWS: 5370\n"
     ]
    }
   ],
   "source": [
    "\n",
    "total_rows = 0\n",
    "# Directory containing CSV files\n",
    "\n",
    "\n",
    "# Ensure the directory exists\n",
    "\n",
    "# if (usingGramFormer): csv_directory += \"_GRAMFORMER\"\n",
    "csv_directory = 'CSVS'\n",
    "os.makedirs(csv_directory, exist_ok=True)\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for i, filename in enumerate(os.listdir(csv_directory)):\n",
    "    # Check if the file is a CSV\n",
    "    if filename.endswith(\".csv\"):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(csv_directory, filename)\n",
    "        \n",
    "        # Read the CSV into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Count the number of rows\n",
    "        num_rows = len(df)\n",
    "        total_rows += num_rows\n",
    "        \n",
    "        # Output the result\n",
    "        print(f'{i+1}. {filename}: {num_rows} rows')\n",
    "\n",
    "print(f'TOTAL ROWS: {total_rows}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SCRATCH WORK--FIXING GRAMMAR</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GRAMMAR FIX TESTING\n",
    "\n",
    "1) stimulating literature, orrisk turning “struggling readers” into “struggling thinkers” by failing to teach themto think critically and intensively about what they read or hear\n",
    "2) Speci ﬁcally, this collection of articles shared a view of relevance as person-centered, complex and multifaceted, important, and mod-iﬁable\n",
    "3) When students and teachers grasp those principles, they can see them re ﬂected in the content and are more likely to recog- nize the value or utility of a speci ﬁc lesson or task meant to build on those principles\n",
    "4) ’s(this issue) conceptualization carries the same conno- tation of a “personally meaningful connection ”(p\n",
    "5) We created a comprehension calibration score for each participant for each medium that cor- responded to the definition of calibration as the difference between predicted and actual perform-ance (Alexander, 2013 ; Fischhoff et al., 1977 ; Glenberg et al., 1987)\n",
    "6) Yet, in multimodal studies employing eye-tracking technology with quite short texts containing carefully positionedvisuals, there were those clusters of students who attended only superficially to the visual content (Mason et al., 2013a,2013b)\n",
    "7) 17 ‘parrhesia’ to describe true speech in which the subject is articulating sincere convictions that they authenticate by their public actions in a context where the act itself pre-supposes an asymmetry of power\n",
    "8) 7 experiences within the socio-political context of their work where they too have been recipients of varied forms of micro-aggression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import language_tool_python\n",
    "# from pyaspeller import YandexSpeller\n",
    "\n",
    "# Load model directly\n",
    "# from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# model_name = \"flexudy/t5-small-wav2vec2-grammar-fixer\"\n",
    "\n",
    "# tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "# from textblob import TextBlob \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: \n",
      "['stimulating literature, orrisk turning “struggling readers” into “struggling thinkers” by failing to teach themto think critically and intensively about what they read or hear', 'Speci ﬁcally, this collection of articles shared a view of relevance as person-centered, complex and multifaceted, important, and mod-iﬁable', 'When students and teachers grasp those principles, they can see them re ﬂected in the content and are more likely to recog- nize the value or utility of a speci ﬁc lesson or task meant to build on those principles', ' ’s(this issue) conceptualization carries the same conno- tation of a “personally meaningful connection ”(p', 'We created a comprehension calibration score for each participant for each medium that cor- responded to the definition of calibration as the difference between predicted and actual perform-ance (Alexander, 2013 ; Fischhoff et al., 1977 ; Glenberg et al., 1987)', 'Yet, in multimodal studies employing eye-tracking technology with quite short texts containing carefully positionedvisuals, there were those clusters of students who attended only superficially to the visual content (Mason et al., 2013a,2013b)', '17 ‘parrhesia’ to describe true speech in which the subject is articulating sincere convictions that they authenticate by their public actions in a context where the act itself pre-supposes an asymmetry of power', '7 experiences within the socio-political context of their work where they too have been recipients of varied forms of micro-aggression']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "sentences = [\"stimulating literature, orrisk turning “struggling readers” into “struggling thinkers” by failing to teach themto think critically and intensively about what they read or hear\",\n",
    "             \"Speci ﬁcally, this collection of articles shared a view of relevance as person-centered, complex and multifaceted, important, and mod-iﬁable\",\n",
    "             \"When students and teachers grasp those principles, they can see them re ﬂected in the content and are more likely to recog- nize the value or utility of a speci ﬁc lesson or task meant to build on those principles\",\n",
    "             \" ’s(this issue) conceptualization carries the same conno- tation of a “personally meaningful connection ”(p\",\n",
    "             \"We created a comprehension calibration score for each participant for each medium that cor- responded to the definition of calibration as the difference between predicted and actual perform-ance (Alexander, 2013 ; Fischhoff et al., 1977 ; Glenberg et al., 1987)\",\n",
    "             \"Yet, in multimodal studies employing eye-tracking technology with quite short texts containing carefully positionedvisuals, there were those clusters of students who attended only superficially to the visual content (Mason et al., 2013a,2013b)\",\n",
    "             \"17 ‘parrhesia’ to describe true speech in which the subject is articulating sincere convictions that they authenticate by their public actions in a context where the act itself pre-supposes an asymmetry of power\",\n",
    "             \"7 experiences within the socio-political context of their work where they too have been recipients of varied forms of micro-aggression\"]\n",
    "\n",
    "print(\"BEFORE: \")\n",
    "fixed = []\n",
    "print(sentences)\n",
    "\n",
    "# def error_correct_pyspeller(sample_text):\n",
    "#     speller = YandexSpeller()\n",
    "#     fixed = speller.spelled(sample_text)\n",
    "#     return fixed\n",
    "\n",
    "# fixer = language_tool_python.LanguageTool(\"en-US\")\n",
    "\n",
    "# def fixed_sentence(sentence: str) -> str:\n",
    "#     # sentence=sentence.replace(\"-\", \"\")\n",
    "#     sentence = re.sub(r\"p\\($\", \"\", sentence)\n",
    "#     sentence = TextBlob(sentence).correct()\n",
    "\n",
    "#     return str(sentence)\n",
    "\n",
    "# for i in range(len(sentences)):\n",
    "#     s = sentences[i]\n",
    "#     fixed.append(fixed_sentence(s))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for original, corrected in zip(sentences, fixed):\n",
    "    print(\"Original Sentence:\\n\"+original)\n",
    "    print(\"Corrected Sentence:\\n\"+corrected)\n",
    "    diff = difflib.unified_diff(\n",
    "        original.split(), corrected.split(),\n",
    "        lineterm='',\n",
    "        fromfile='Original',\n",
    "        tofile='Corrected'\n",
    "    )\n",
    "    print(\"\\n\".join(diff))\n",
    "    print(\"---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
